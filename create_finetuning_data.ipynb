{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load the dataset into pandas dataframe\n",
    "\n",
    "def squad_json_to_dataframe(file_path, record_path=['data','paragraphs','qas','answers']):\n",
    "    \"\"\"\n",
    "    input_file_path: path to the squad json file.\n",
    "    record_path: path to deepest level in json file default value is\n",
    "    ['data','paragraphs','qas','answers']\n",
    "    \"\"\"\n",
    "    file = json.loads(open(file_path).read())\n",
    "    # parsing different level's in the json file\n",
    "    js = pd.json_normalize(file, record_path)\n",
    "    m = pd.json_normalize(file, record_path[:-1])\n",
    "    r = pd.json_normalize(file,record_path[:-2])\n",
    "    # combining it into single dataframe\n",
    "    idx = np.repeat(r['context'].values, r.qas.str.len())\n",
    "    m['context'] = idx\n",
    "    data = m[['id','question','context','answers']].set_index('id').reset_index()\n",
    "    data['c_id'] = data['context'].factorize()[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'/home/harshad/workspace/OpenAI/repo_qa/Context-QuestionAnswer/Data/train-v1.1.json'\n",
    "df=squad_json_to_dataframe(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the data and keeping the required columns\n",
    "df['answers'] = df['answers'].apply(lambda x: x[0]['text'])\n",
    "\n",
    "#there are multiple questinons available for each context. We will use only one question for each context\n",
    "df.drop_duplicates(subset=['c_id'],keep='last',inplace=True)\n",
    "\n",
    "df.drop(['id','c_id'],axis=1,inplace=True)\n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using only first 500 sample for sake of demo purpose. Using all of the data will incure quite a some costs\n",
    "df = df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we check that he separator we intend to use isn't present within the contexts\n",
    "df.context.str.contains('->').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('fraction_of_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In what year did the student paper Common Sens...</td>\n",
       "      <td>As at most other universities, Notre Dame's st...</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which prize did Frederick Buechner create?</td>\n",
       "      <td>The university is the major seat of the Congre...</td>\n",
       "      <td>Buechner Prize for Preaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The College of Science began to offer civil en...</td>\n",
       "      <td>The College of Engineering was established in ...</td>\n",
       "      <td>the 1870s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which organization declared the First Year of ...</td>\n",
       "      <td>All of Notre Dame's undergraduate students are...</td>\n",
       "      <td>U.S. News &amp; World Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Which department at Notre Dame is the only one...</td>\n",
       "      <td>The university first offered graduate degrees,...</td>\n",
       "      <td>Department of Pre-Professional Studies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What company did Ray Kroc own?</td>\n",
       "      <td>The Joan B. Kroc Institute for International P...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is a common name to reference the mural c...</td>\n",
       "      <td>The library system of the university is divide...</td>\n",
       "      <td>Touchdown Jesus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How many miles does the average student at Not...</td>\n",
       "      <td>Notre Dame is known for its competitive admiss...</td>\n",
       "      <td>more than 750 miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What percentage of Notre Dame students decide ...</td>\n",
       "      <td>In 2015-2016, Notre Dame ranked 18th overall a...</td>\n",
       "      <td>57.6%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What sits on top of the Main Building at Notre...   \n",
       "1  In what year did the student paper Common Sens...   \n",
       "2         Which prize did Frederick Buechner create?   \n",
       "3  The College of Science began to offer civil en...   \n",
       "4  Which organization declared the First Year of ...   \n",
       "5  Which department at Notre Dame is the only one...   \n",
       "6                     What company did Ray Kroc own?   \n",
       "7  What is a common name to reference the mural c...   \n",
       "8  How many miles does the average student at Not...   \n",
       "9  What percentage of Notre Dame students decide ...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  As at most other universities, Notre Dame's st...   \n",
       "2  The university is the major seat of the Congre...   \n",
       "3  The College of Engineering was established in ...   \n",
       "4  All of Notre Dame's undergraduate students are...   \n",
       "5  The university first offered graduate degrees,...   \n",
       "6  The Joan B. Kroc Institute for International P...   \n",
       "7  The library system of the university is divide...   \n",
       "8  Notre Dame is known for its competitive admiss...   \n",
       "9  In 2015-2016, Notre Dame ranked 18th overall a...   \n",
       "\n",
       "                                  answers  \n",
       "0      a golden statue of the Virgin Mary  \n",
       "1                                    1987  \n",
       "2            Buechner Prize for Preaching  \n",
       "3                               the 1870s  \n",
       "4                U.S. News & World Report  \n",
       "5  Department of Pre-Professional Studies  \n",
       "6                              McDonald's  \n",
       "7                         Touchdown Jesus  \n",
       "8                     more than 750 miles  \n",
       "9                                   57.6%  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spliting the data on train and test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fine_tuning_dataset(df, discriminator=False, n_negative=1, add_related=False):\n",
    "    \"\"\"\n",
    "    Create a dataset for fine tuning the OpenAI model; either for a discriminator model, \n",
    "    or a model specializing in Q&A, where it says if no relevant context is found.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        The dataframe containing the question, answer and context pairs\n",
    "    discriminator: bool\n",
    "        Whether to create a dataset for the discriminator\n",
    "    n_negative: int\n",
    "        The number of random negative samples to add (using a random context)\n",
    "    add_related: bool\n",
    "        Whether to add the related contexts to the correct context. These are hard negative examples\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The dataframe containing the prompts and completions, ready for fine-tuning\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for i, row in df.iterrows():\n",
    "        for q, a in zip((\"1.\" + row.question).split('\\n'), (\"1.\" + row.ans).split('\\n')):\n",
    "            if len(q) >10 and len(a) >10:\n",
    "                if discriminator:\n",
    "                    rows.append({\"prompt\":f\"{row.context}\\nQuestion: {q[2:].strip()}\\n Related:\", \"completion\":f\" yes\"})\n",
    "                else:\n",
    "                    rows.append({\"prompt\":f\"{row.context}\\nQuestion: {q[2:].strip()}\\nAnswer:\", \"completion\":f\" {a[2:].strip()}\"})\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        for q in (\"1.\" + row.question).split('\\n'):\n",
    "            if len(q) >10:\n",
    "                for j in range(n_negative + (2 if add_related else 0)):\n",
    "                    random_context = \"\"\n",
    "                    if j == 0 and add_related:\n",
    "                        continue\n",
    "                        # add the related contexts based on originating from the same wikipedia page\n",
    "                        subset = df[(df.title == row.title) & (df.context != row.context)]\n",
    "                        \n",
    "                        if len(subset) < 1:\n",
    "                            continue\n",
    "                        random_context = subset.sample(1).iloc[0].context\n",
    "                    if j == 1 and add_related:\n",
    "                        pass\n",
    "                        # add the related contexts based on the most similar contexts according to the search\n",
    "                        # random_context = get_random_similar_contexts(q[2:].strip(), row.context, search_model='ada', max_rerank=10)\n",
    "                    else:\n",
    "                        while True:\n",
    "                            # add random context, which isn't the correct context\n",
    "                            random_context = df.sample(1).iloc[0].context\n",
    "                            if random_context != row.context:\n",
    "                                break\n",
    "                    if discriminator:\n",
    "                        rows.append({\"prompt\":f\"{random_context}\\nQuestion: {q[2:].strip()}\\n Related:\", \"completion\":f\" no\"})\n",
    "                    else:\n",
    "                        rows.append({\"prompt\":f\"{random_context}\\nQuestion: {q[2:].strip()}\\nAnswer:\", \"completion\":f\" No appropriate context found to answer the question.\"})\n",
    "\n",
    "    return pd.DataFrame(rows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data to train two question answer model and discriminator model\n",
    "# this will dump 4 jsonl files. train jsonl and test jsonl for each model\n",
    "for name, is_disc in [('discriminator', True), ('qa', False)]:\n",
    "    for train_test, dt in [('train', train_df), ('test', test_df)]:\n",
    "        ft = create_fine_tuning_dataset(dt, discriminator=is_disc, n_negative=1, add_related=False)\n",
    "        ft.to_json(f'{name}_{train_test}.jsonl', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6b8e43ebc2a0c7ddba41e90ef0ee8b21ec00264271a4513648528c2def0d6ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
